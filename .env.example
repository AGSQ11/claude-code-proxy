# Global/Fallback API Settings
# OPENAI_API_KEY is used as fallback for any model tier that doesn't have its own key
# It can be omitted if you configure all three model-specific keys below (BIG/MIDDLE/SMALL_MODEL_API_KEY)
OPENAI_API_KEY="sk-your-openai-api-key-here"

# Optional: Expected Anthropic API key for client validation
# If set, clients must provide this exact API key to access the proxy
ANTHROPIC_API_KEY="your-expected-anthropic-api-key"

# Optional: OpenAI API base URL (default: https://api.openai.com/v1)
# This is the fallback base URL used for any model tier that doesn't have its own URL
OPENAI_BASE_URL="https://api.openai.com/v1"

# Optional: Model mappings (BIG, MIDDLE, and SMALL models)
BIG_MODEL="gpt-4o"
# Used for Claude opus requests
MIDDLE_MODEL="gpt-4o"
# Used for Claude sonnet requests
SMALL_MODEL="gpt-4o-mini"
# Used for Claude haiku requests

# ============================================================================
# ADVANCED: Per-Model Provider Configuration
# ============================================================================
# You can configure different providers for each model tier (BIG/MIDDLE/SMALL)
# If not set, these will fall back to the global OPENAI_* settings above

# BIG Model Provider Settings (for Claude Opus)
# BIG_MODEL_API_KEY="sk-different-api-key"
# BIG_MODEL_BASE_URL="https://api.openai.com/v1"
# BIG_MODEL_AZURE_API_VERSION="2024-03-01-preview"

# MIDDLE Model Provider Settings (for Claude Sonnet)
# MIDDLE_MODEL_API_KEY="sk-another-api-key"
# MIDDLE_MODEL_BASE_URL="https://api.openai.com/v1"
# MIDDLE_MODEL_AZURE_API_VERSION="2024-03-01-preview"

# SMALL Model Provider Settings (for Claude Haiku)
# SMALL_MODEL_API_KEY="sk-yet-another-api-key"
# SMALL_MODEL_BASE_URL="https://api.openai.com/v1"
# SMALL_MODEL_AZURE_API_VERSION="2024-03-01-preview"

# Optional: Server settings
HOST="0.0.0.0"
PORT="8082"
LOG_LEVEL="INFO"  
# DEBUG, INFO, WARNING, ERROR, CRITICAL

# Optional: Performance settings  
MAX_TOKENS_LIMIT="4096"
# Minimum tokens limit for requests (to avoid errors with thinking model)
MIN_TOKENS_LIMIT="4096"
REQUEST_TIMEOUT="90"
MAX_RETRIES="2"

# Examples for other providers:

# For Azure OpenAI (recommended if OpenAI is not available in your region):
# OPENAI_API_KEY="your-azure-api-key"
# OPENAI_BASE_URL="https://your-resource-name.openai.azure.com/openai/deployments/your-deployment-name"
# AZURE_API_VERSION="2024-03-01-preview"
# BIG_MODEL="gpt-4"
# MIDDLE_MODEL="gpt-4"
# SMALL_MODEL="gpt-35-turbo"

# For local models (like Ollama):
# OPENAI_API_KEY="dummy-key"  # Required but can be any value for local models
# OPENAI_BASE_URL="http://localhost:11434/v1"
# BIG_MODEL="llama3.1:70b"
# MIDDLE_MODEL="llama3.1:70b"
# SMALL_MODEL="llama3.1:8b"

# Note: If you get "unsupported_country_region_territory" errors,
# consider using Azure OpenAI or a local model setup instead.


# Custom Headers Configuration
# Format: CUSTOM_HEADER_HEADER_NAME=header_value
# These headers will be automatically included in API requests to all models
# Uncomment the lines below to use custom headers:
# CUSTOM_HEADER_ACCEPT="application/jsonstream"
# CUSTOM_HEADER_CONTENT_TYPE="application/json"
# CUSTOM_HEADER_USER_AGENT="node-fetch"
# CUSTOM_HEADER_HOST="example.com"
# CUSTOM_HEADER_X_API_KEY="your-api-key"
# CUSTOM_HEADER_X_CLIENT_ID="your-client-id"

# Per-Model Custom Headers (optional, override global headers)
# Format: CUSTOM_HEADER_{MODEL_TIER}_MODEL_HEADER_NAME=header_value
# CUSTOM_HEADER_BIG_MODEL_X_API_KEY="big-model-api-key"
# CUSTOM_HEADER_MIDDLE_MODEL_X_API_KEY="middle-model-api-key"
# CUSTOM_HEADER_SMALL_MODEL_X_API_KEY="small-model-api-key"

# ============================================================================
# EXAMPLE CONFIGURATIONS
# ============================================================================

# Example 1: Use OpenAI for all models (default)
# OPENAI_API_KEY="sk-your-openai-key"
# OPENAI_BASE_URL="https://api.openai.com/v1"
# BIG_MODEL="gpt-4o"
# MIDDLE_MODEL="gpt-4o"
# SMALL_MODEL="gpt-4o-mini"

# Example 2: Mix OpenAI and local Ollama
# Global settings (used by BIG and MIDDLE)
# OPENAI_API_KEY="sk-your-openai-key"
# OPENAI_BASE_URL="https://api.openai.com/v1"
# BIG_MODEL="gpt-4o"
# MIDDLE_MODEL="gpt-4o"
#
# SMALL model uses local Ollama
# SMALL_MODEL="llama3.1:8b"
# SMALL_MODEL_API_KEY="dummy-key"
# SMALL_MODEL_BASE_URL="http://localhost:11434/v1"

# Example 3: Different providers for each tier
# BIG uses Azure OpenAI
# BIG_MODEL="gpt-4"
# BIG_MODEL_API_KEY="your-azure-key"
# BIG_MODEL_BASE_URL="https://your-resource.openai.azure.com/openai/deployments/gpt-4"
# BIG_MODEL_AZURE_API_VERSION="2024-03-01-preview"
#
# MIDDLE uses OpenAI
# MIDDLE_MODEL="gpt-4o"
# MIDDLE_MODEL_API_KEY="sk-your-openai-key"
# MIDDLE_MODEL_BASE_URL="https://api.openai.com/v1"
#
# SMALL uses local Ollama
# SMALL_MODEL="llama3.1:8b"
# SMALL_MODEL_API_KEY="dummy-key"
# SMALL_MODEL_BASE_URL="http://localhost:11434/v1"
